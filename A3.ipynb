{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we convert imbalanced dataset into balanced dataset\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('C:/Users/jmk/OneDrive/Desktop/credit card fraud detection/Creditcard_data.csv')\n",
    "\n",
    "# Split dataset into input features and labels\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Apply Random Over Sampling to balance the dataset\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Save the balanced dataset to a new CSV file\n",
    "balanced_data = pd.concat([pd.DataFrame(X_resampled), pd.DataFrame(y_resampled)], axis=1)\n",
    "balanced_data.to_csv('balanced_creditcard.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>529</td>\n",
       "      <td>-2.000567</td>\n",
       "      <td>-2.495484</td>\n",
       "      <td>2.467149</td>\n",
       "      <td>1.140053</td>\n",
       "      <td>2.462010</td>\n",
       "      <td>0.594262</td>\n",
       "      <td>-2.110183</td>\n",
       "      <td>0.788347</td>\n",
       "      <td>0.958809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422452</td>\n",
       "      <td>1.195394</td>\n",
       "      <td>0.297836</td>\n",
       "      <td>-0.857105</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>0.861019</td>\n",
       "      <td>-0.124622</td>\n",
       "      <td>-0.171060</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>164</td>\n",
       "      <td>0.073497</td>\n",
       "      <td>0.551033</td>\n",
       "      <td>0.451890</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.822947</td>\n",
       "      <td>0.251480</td>\n",
       "      <td>0.296319</td>\n",
       "      <td>0.139497</td>\n",
       "      <td>-0.123050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128758</td>\n",
       "      <td>-0.381932</td>\n",
       "      <td>0.151012</td>\n",
       "      <td>-1.363967</td>\n",
       "      <td>-1.389079</td>\n",
       "      <td>0.075412</td>\n",
       "      <td>0.231750</td>\n",
       "      <td>0.230171</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>164</td>\n",
       "      <td>0.073497</td>\n",
       "      <td>0.551033</td>\n",
       "      <td>0.451890</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.822947</td>\n",
       "      <td>0.251480</td>\n",
       "      <td>0.296319</td>\n",
       "      <td>0.139497</td>\n",
       "      <td>-0.123050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128758</td>\n",
       "      <td>-0.381932</td>\n",
       "      <td>0.151012</td>\n",
       "      <td>-1.363967</td>\n",
       "      <td>-1.389079</td>\n",
       "      <td>0.075412</td>\n",
       "      <td>0.231750</td>\n",
       "      <td>0.230171</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>539</td>\n",
       "      <td>-1.738582</td>\n",
       "      <td>0.052740</td>\n",
       "      <td>1.187057</td>\n",
       "      <td>-0.656652</td>\n",
       "      <td>0.920623</td>\n",
       "      <td>-0.291788</td>\n",
       "      <td>0.269083</td>\n",
       "      <td>0.140631</td>\n",
       "      <td>0.023464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179545</td>\n",
       "      <td>-0.192036</td>\n",
       "      <td>-0.261879</td>\n",
       "      <td>-0.237477</td>\n",
       "      <td>-0.335040</td>\n",
       "      <td>0.240323</td>\n",
       "      <td>-0.345129</td>\n",
       "      <td>-0.383563</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>472</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1526 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0        0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2        1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3        1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4        2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "1521   529 -2.000567 -2.495484  2.467149  1.140053  2.462010  0.594262   \n",
       "1522   164  0.073497  0.551033  0.451890  0.114964  0.822947  0.251480   \n",
       "1523   164  0.073497  0.551033  0.451890  0.114964  0.822947  0.251480   \n",
       "1524   539 -1.738582  0.052740  1.187057 -0.656652  0.920623 -0.291788   \n",
       "1525   472 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0     0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1    -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2     0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3     0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4     0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1521 -2.110183  0.788347  0.958809  ...  0.422452  1.195394  0.297836   \n",
       "1522  0.296319  0.139497 -0.123050  ... -0.128758 -0.381932  0.151012   \n",
       "1523  0.296319  0.139497 -0.123050  ... -0.128758 -0.381932  0.151012   \n",
       "1524  0.269083  0.140631  0.023464  ... -0.179545 -0.192036 -0.261879   \n",
       "1525  0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "\n",
       "           V24       V25       V26       V27       V28  Amount  Class  \n",
       "0     0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1    -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2    -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3    -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4     0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "...        ...       ...       ...       ...       ...     ...    ...  \n",
       "1521 -0.857105 -0.219322  0.861019 -0.124622 -0.171060    1.50      1  \n",
       "1522 -1.363967 -1.389079  0.075412  0.231750  0.230171    0.99      1  \n",
       "1523 -1.363967 -1.389079  0.075412  0.231750  0.230171    0.99      1  \n",
       "1524 -0.237477 -0.335040  0.240323 -0.345129 -0.383563    1.00      1  \n",
       "1525 -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "\n",
       "[1526 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size for random sampling:  308\n"
     ]
    }
   ],
   "source": [
    "#Sample size for random sampling\n",
    "\n",
    "# Import necessary libraries\n",
    "import math\n",
    "\n",
    "# Define the desired level of confidence and margin of error\n",
    "confidence_level = 0.95\n",
    "margin_of_error = 0.05\n",
    "\n",
    "# Load the balanced dataset and get the total population size\n",
    "balanced_data = pd.read_csv('balanced_creditcard.csv')\n",
    "total_population = balanced_data.shape[0]\n",
    "\n",
    "# Calculate the sample size using the formula\n",
    "sample_size = (1.96**2 * 0.5 * 0.5 * total_population) / ((margin_of_error**2 * (total_population - 1)) + (1.96**2 * 0.5 * 0.5))\n",
    "\n",
    "# Round up the sample size to the nearest integer\n",
    "sample_size1 = math.ceil(sample_size)\n",
    "\n",
    "# Print the sample size\n",
    "print(\"Sample size for random sampling: \", sample_size1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>164</td>\n",
       "      <td>0.073497</td>\n",
       "      <td>0.551033</td>\n",
       "      <td>0.451890</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.822947</td>\n",
       "      <td>0.251480</td>\n",
       "      <td>0.296319</td>\n",
       "      <td>0.139497</td>\n",
       "      <td>-0.123050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128758</td>\n",
       "      <td>-0.381932</td>\n",
       "      <td>0.151012</td>\n",
       "      <td>-1.363967</td>\n",
       "      <td>-1.389079</td>\n",
       "      <td>0.075412</td>\n",
       "      <td>0.231750</td>\n",
       "      <td>0.230171</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.549626</td>\n",
       "      <td>0.418949</td>\n",
       "      <td>1.729833</td>\n",
       "      <td>0.203065</td>\n",
       "      <td>-0.187012</td>\n",
       "      <td>0.253878</td>\n",
       "      <td>0.500894</td>\n",
       "      <td>0.251256</td>\n",
       "      <td>-0.227985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115062</td>\n",
       "      <td>0.418529</td>\n",
       "      <td>-0.065133</td>\n",
       "      <td>0.264981</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.395969</td>\n",
       "      <td>0.027182</td>\n",
       "      <td>0.043506</td>\n",
       "      <td>59.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>118</td>\n",
       "      <td>1.254914</td>\n",
       "      <td>0.350287</td>\n",
       "      <td>0.302488</td>\n",
       "      <td>0.693114</td>\n",
       "      <td>-0.371470</td>\n",
       "      <td>-1.070256</td>\n",
       "      <td>0.086781</td>\n",
       "      <td>-0.202836</td>\n",
       "      <td>0.035154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287592</td>\n",
       "      <td>-0.832682</td>\n",
       "      <td>0.128083</td>\n",
       "      <td>0.339427</td>\n",
       "      <td>0.215944</td>\n",
       "      <td>0.094704</td>\n",
       "      <td>-0.023354</td>\n",
       "      <td>0.030892</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>499</td>\n",
       "      <td>1.255439</td>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.292700</td>\n",
       "      <td>0.699873</td>\n",
       "      <td>-0.428876</td>\n",
       "      <td>-1.088456</td>\n",
       "      <td>0.043840</td>\n",
       "      <td>-0.167739</td>\n",
       "      <td>0.128854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294795</td>\n",
       "      <td>-0.882126</td>\n",
       "      <td>0.136846</td>\n",
       "      <td>0.327949</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.096516</td>\n",
       "      <td>-0.027271</td>\n",
       "      <td>0.029491</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>539</td>\n",
       "      <td>-1.738582</td>\n",
       "      <td>0.052740</td>\n",
       "      <td>1.187057</td>\n",
       "      <td>-0.656652</td>\n",
       "      <td>0.920623</td>\n",
       "      <td>-0.291788</td>\n",
       "      <td>0.269083</td>\n",
       "      <td>0.140631</td>\n",
       "      <td>0.023464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179545</td>\n",
       "      <td>-0.192036</td>\n",
       "      <td>-0.261879</td>\n",
       "      <td>-0.237477</td>\n",
       "      <td>-0.335040</td>\n",
       "      <td>0.240323</td>\n",
       "      <td>-0.345129</td>\n",
       "      <td>-0.383563</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>472</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>155</td>\n",
       "      <td>1.171954</td>\n",
       "      <td>0.311213</td>\n",
       "      <td>0.313605</td>\n",
       "      <td>0.519230</td>\n",
       "      <td>-0.058032</td>\n",
       "      <td>-0.258769</td>\n",
       "      <td>-0.043843</td>\n",
       "      <td>0.039599</td>\n",
       "      <td>-0.344227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200153</td>\n",
       "      <td>-0.541916</td>\n",
       "      <td>0.137491</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>0.139121</td>\n",
       "      <td>0.104376</td>\n",
       "      <td>-0.005414</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>484</td>\n",
       "      <td>-0.928088</td>\n",
       "      <td>0.398194</td>\n",
       "      <td>1.741131</td>\n",
       "      <td>0.182673</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>-0.901004</td>\n",
       "      <td>0.879016</td>\n",
       "      <td>-0.156590</td>\n",
       "      <td>-0.142117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066353</td>\n",
       "      <td>0.281378</td>\n",
       "      <td>-0.257966</td>\n",
       "      <td>0.385384</td>\n",
       "      <td>0.391117</td>\n",
       "      <td>-0.453853</td>\n",
       "      <td>-0.104448</td>\n",
       "      <td>-0.125765</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>130</td>\n",
       "      <td>-0.485238</td>\n",
       "      <td>0.658497</td>\n",
       "      <td>1.949967</td>\n",
       "      <td>1.249695</td>\n",
       "      <td>0.426410</td>\n",
       "      <td>0.231513</td>\n",
       "      <td>0.585115</td>\n",
       "      <td>0.029163</td>\n",
       "      <td>-0.520297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>0.328244</td>\n",
       "      <td>-0.232563</td>\n",
       "      <td>0.225572</td>\n",
       "      <td>0.025892</td>\n",
       "      <td>-0.247395</td>\n",
       "      <td>-0.025381</td>\n",
       "      <td>-0.118565</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>561</td>\n",
       "      <td>1.214872</td>\n",
       "      <td>0.307970</td>\n",
       "      <td>0.278629</td>\n",
       "      <td>0.642981</td>\n",
       "      <td>-0.185161</td>\n",
       "      <td>-0.603602</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>-0.064239</td>\n",
       "      <td>0.030872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260682</td>\n",
       "      <td>-0.716148</td>\n",
       "      <td>0.159804</td>\n",
       "      <td>0.033516</td>\n",
       "      <td>0.143170</td>\n",
       "      <td>0.124259</td>\n",
       "      <td>-0.006506</td>\n",
       "      <td>0.027226</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        V1        V2        V3        V4        V5        V6  \\\n",
       "1439   164  0.073497  0.551033  0.451890  0.114964  0.822947  0.251480   \n",
       "76      49 -0.549626  0.418949  1.729833  0.203065 -0.187012  0.253878   \n",
       "1010   118  1.254914  0.350287  0.302488  0.693114 -0.371470 -1.070256   \n",
       "660    499  1.255439  0.307729  0.292700  0.699873 -0.428876 -1.088456   \n",
       "1132   539 -1.738582  0.052740  1.187057 -0.656652  0.920623 -0.291788   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "855    472 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "233    155  1.171954  0.311213  0.313605  0.519230 -0.058032 -0.258769   \n",
       "1475   484 -0.928088  0.398194  1.741131  0.182673  0.966387 -0.901004   \n",
       "196    130 -0.485238  0.658497  1.949967  1.249695  0.426410  0.231513   \n",
       "752    561  1.214872  0.307970  0.278629  0.642981 -0.185161 -0.603602   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "1439  0.296319  0.139497 -0.123050  ... -0.128758 -0.381932  0.151012   \n",
       "76    0.500894  0.251256 -0.227985  ...  0.115062  0.418529 -0.065133   \n",
       "1010  0.086781 -0.202836  0.035154  ... -0.287592 -0.832682  0.128083   \n",
       "660   0.043840 -0.167739  0.128854  ... -0.294795 -0.882126  0.136846   \n",
       "1132  0.269083  0.140631  0.023464  ... -0.179545 -0.192036 -0.261879   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "855   0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "233  -0.043843  0.039599 -0.344227  ... -0.200153 -0.541916  0.137491   \n",
       "1475  0.879016 -0.156590 -0.142117  ...  0.066353  0.281378 -0.257966   \n",
       "196   0.585115  0.029163 -0.520297  ...  0.007290  0.328244 -0.232563   \n",
       "752   0.006881 -0.064239  0.030872  ... -0.260682 -0.716148  0.159804   \n",
       "\n",
       "           V24       V25       V26       V27       V28  Amount  Class  \n",
       "1439 -1.363967 -1.389079  0.075412  0.231750  0.230171    0.99      1  \n",
       "76    0.264981  0.003958  0.395969  0.027182  0.043506   59.99      0  \n",
       "1010  0.339427  0.215944  0.094704 -0.023354  0.030892    2.69      1  \n",
       "660   0.327949  0.194459  0.096516 -0.027271  0.029491    1.98      0  \n",
       "1132 -0.237477 -0.335040  0.240323 -0.345129 -0.383563    1.00      1  \n",
       "...        ...       ...       ...       ...       ...     ...    ...  \n",
       "855  -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "233  -0.001739  0.139121  0.104376 -0.005414  0.018728    1.29      0  \n",
       "1475  0.385384  0.391117 -0.453853 -0.104448 -0.125765    1.00      1  \n",
       "196   0.225572  0.025892 -0.247395 -0.025381 -0.118565    5.97      0  \n",
       "752   0.033516  0.143170  0.124259 -0.006506  0.027226    0.89      0  \n",
       "\n",
       "[308 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Define the sample size calculated in the previous step\n",
    "sample_size1 = 308\n",
    "\n",
    "# Perform random sampling of the dataset\n",
    "random_sample = balanced_data.sample(n=sample_size1, random_state=42)\n",
    "\n",
    "# Save the random sample to a new CSV file\n",
    "random_sample.to_csv('creditcard_random_sample.csv', index=False)\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Random forest classifier\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the random sample dataset\n",
    "random_sample = pd.read_csv('creditcard_random_sample.csv')\n",
    "\n",
    "# Split the dataset into input features and labels\n",
    "X = random_sample.iloc[:, :-1]\n",
    "y = random_sample.iloc[:, -1]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit a random forest classifier to the training set\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6129032258064516\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Fit a support vector machine classifier to the training set\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8870967741935484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Fit a logistic regression classifier to the training set\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.967741935483871\n"
     ]
    }
   ],
   "source": [
    "#KNN Classifier \n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Fit a k-nearest neighbors classifier to the training set\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.967741935483871\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the random sample dataset\n",
    "random_sample = pd.read_csv('creditcard_random_sample.csv')\n",
    "\n",
    "# Split the dataset into input features and labels\n",
    "X = random_sample.iloc[:, :-1]\n",
    "y = random_sample.iloc[:, -1]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit a decision tree classifier to the training set\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size for fraudulent transactions:  1\n",
      "Sample size for non-fraudulent transactions:  1\n"
     ]
    }
   ],
   "source": [
    "#Sample size for stratified sampling\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the balanced credit card dataset\n",
    "balanced_data = pd.read_csv('balanced_creditcard.csv')\n",
    "\n",
    "# Calculate the proportion of each class in the population\n",
    "fraudulent_proportion = len(balanced_data[balanced_data['Class'] == 1]) / len(balanced_data)\n",
    "nonfraudulent_proportion = len(balanced_data[balanced_data['Class'] == 0]) / len(balanced_data)\n",
    "\n",
    "# Define the desired level of confidence and margin of error\n",
    "confidence_level = 0.95\n",
    "margin_of_error = 0.05\n",
    "\n",
    "# Calculate the z-score for the desired level of confidence\n",
    "z_score = 1.96\n",
    "\n",
    "# Calculate the sample size for each class using the formula for stratified sampling\n",
    "fraudulent_sample_size = int(round((len(balanced_data) * fraudulent_proportion * z_score**2) / (margin_of_error**2 + fraudulent_proportion * (len(balanced_data) - 1) * z_score**2)))\n",
    "nonfraudulent_sample_size = int(round((len(balanced_data) * nonfraudulent_proportion * z_score**2) / (margin_of_error**2 + nonfraudulent_proportion * (len(balanced_data) - 1) * z_score**2)))\n",
    "\n",
    "# Print the sample sizes\n",
    "print(\"Sample size for fraudulent transactions: \", fraudulent_sample_size)\n",
    "print(\"Sample size for non-fraudulent transactions: \", nonfraudulent_sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of stratified sample:  (2, 31)\n",
      "Shape of X_train:  (1, 30)\n",
      "Shape of X_test:  (1, 30)\n",
      "Shape of y_train:  (1,)\n",
      "Shape of y_test:  (1,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>164</td>\n",
       "      <td>0.073497</td>\n",
       "      <td>0.551033</td>\n",
       "      <td>0.451890</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.822947</td>\n",
       "      <td>0.251480</td>\n",
       "      <td>0.296319</td>\n",
       "      <td>0.139497</td>\n",
       "      <td>-0.12305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128758</td>\n",
       "      <td>-0.381932</td>\n",
       "      <td>0.151012</td>\n",
       "      <td>-1.363967</td>\n",
       "      <td>-1.389079</td>\n",
       "      <td>0.075412</td>\n",
       "      <td>0.231750</td>\n",
       "      <td>0.230171</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>265</td>\n",
       "      <td>-0.491003</td>\n",
       "      <td>0.906953</td>\n",
       "      <td>1.645423</td>\n",
       "      <td>-0.083531</td>\n",
       "      <td>-0.195560</td>\n",
       "      <td>-0.710165</td>\n",
       "      <td>0.559119</td>\n",
       "      <td>0.116340</td>\n",
       "      <td>-0.53819</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168067</td>\n",
       "      <td>-0.517387</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>0.491652</td>\n",
       "      <td>-0.277795</td>\n",
       "      <td>0.043841</td>\n",
       "      <td>0.253372</td>\n",
       "      <td>0.111749</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        V1        V2        V3        V4        V5        V6  \\\n",
       "1120   164  0.073497  0.551033  0.451890  0.114964  0.822947  0.251480   \n",
       "360    265 -0.491003  0.906953  1.645423 -0.083531 -0.195560 -0.710165   \n",
       "\n",
       "            V7        V8       V9  ...       V21       V22       V23  \\\n",
       "1120  0.296319  0.139497 -0.12305  ... -0.128758 -0.381932  0.151012   \n",
       "360   0.559119  0.116340 -0.53819  ... -0.168067 -0.517387  0.018650   \n",
       "\n",
       "           V24       V25       V26       V27       V28  Amount  Class  \n",
       "1120 -1.363967 -1.389079  0.075412  0.231750  0.230171    0.99      1  \n",
       "360   0.491652 -0.277795  0.043841  0.253372  0.111749    9.03      0  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stratified sampling\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the sample sizes\n",
    "fraudulent_sample_size = 1\n",
    "nonfraudulent_sample_size = 1\n",
    "\n",
    "# Perform stratified sampling on the balanced dataset\n",
    "fraudulent_data = balanced_data[balanced_data['Class'] == 1].sample(n=fraudulent_sample_size, random_state=42)\n",
    "nonfraudulent_data = balanced_data[balanced_data['Class'] == 0].sample(n=nonfraudulent_sample_size, random_state=42)\n",
    "\n",
    "# Concatenate the fraudulent and non-fraudulent samples\n",
    "stratified_sample = pd.concat([fraudulent_data, nonfraudulent_data])\n",
    "\n",
    "# Split the stratified sample into training and testing sets\n",
    "X = stratified_sample.drop('Class', axis=1)\n",
    "y = stratified_sample['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shape of the stratified sample and the training/testing sets\n",
    "print(\"Shape of stratified sample: \", stratified_sample.shape)\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(\"Shape of y_test: \", y_test.shape)\n",
    "\n",
    "stratified_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the random forest classifier on the stratified sample:  0.0\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the sample sizes for stratified sampling\n",
    "fraudulent_sample_size = 1\n",
    "nonfraudulent_sample_size = 1\n",
    "\n",
    "# Perform stratified sampling on the balanced dataset\n",
    "fraudulent_data = balanced_data[balanced_data['Class'] == 1].sample(n=fraudulent_sample_size, random_state=42)\n",
    "nonfraudulent_data = balanced_data[balanced_data['Class'] == 0].sample(n=nonfraudulent_sample_size, random_state=42)\n",
    "stratified_sample = pd.concat([fraudulent_data, nonfraudulent_data])\n",
    "\n",
    "# Split the stratified sample into training and testing sets\n",
    "X = stratified_sample.drop('Class', axis=1)\n",
    "y = stratified_sample['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a random forest classifier on the training set\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model on the testing set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the random forest classifier on the stratified sample: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Predict the labels for the testing set\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     17\u001b[0m \u001b[39m# Calculate the accuracy of the model on the testing set\u001b[39;00m\n\u001b[0;32m     18\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\jmk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:234\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    232\u001b[0m     \u001b[39m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[39m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    235\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jmk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:810\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    808\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[0;32m    809\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n\u001b[1;32m--> 810\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    811\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected n_neighbors <= n_samples, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    812\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but n_samples = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, n_neighbors = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_samples_fit, n_neighbors)\n\u001b[0;32m    813\u001b[0m     )\n\u001b[0;32m    815\u001b[0m n_jobs \u001b[39m=\u001b[39m effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[0;32m    816\u001b[0m chunked_results \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5"
     ]
    }
   ],
   "source": [
    "#Knn Classifier\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the balanced credit card dataset\n",
    "balanced_data = pd.read_csv('balanced_creditcard.csv')\n",
    "\n",
    "# Train a KNN classifier on the training set\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model on the testing set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the KNN classifier on the stratified sample: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes classifier on the stratified sample:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "c:\\Users\\jmk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "c:\\Users\\jmk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the sample sizes for stratified sampling\n",
    "fraudulent_sample_size = 1\n",
    "nonfraudulent_sample_size = 1\n",
    "\n",
    "# Train a Naive Bayes classifier on the training set\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model on the testing set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the Naive Bayes classifier on the stratified sample: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sampling interval for systematic sampling is: 4\n"
     ]
    }
   ],
   "source": [
    "#Systematic Sampling\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Calculate the size of the dataset\n",
    "N = len(balanced_data)\n",
    "\n",
    "# Define the desired sample size\n",
    "n = 308\n",
    "\n",
    "# Calculate the sampling interval\n",
    "k = math.floor(N / n)\n",
    "\n",
    "# Print the sampling interval\n",
    "print(\"The sampling interval for systematic sampling is:\", k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0        0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
      "4        2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
      "8        7 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818   \n",
      "12      10  1.249999 -1.221637  0.383930 -1.234899 -1.485419 -0.753230   \n",
      "16      12  1.103215 -0.040296  1.267332  1.289091 -0.735997  0.288069   \n",
      "...    ...       ...       ...       ...       ...       ...       ...   \n",
      "1508   472 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
      "1512   484 -0.928088  0.398194  1.741131  0.182673  0.966387 -0.901004   \n",
      "1516   529 -2.000567 -2.495484  2.467149  1.140053  2.462010  0.594262   \n",
      "1520   574  1.257719  0.364739  0.306923  0.690638 -0.357792 -1.067481   \n",
      "1524   539 -1.738582  0.052740  1.187057 -0.656652  0.920623 -0.291788   \n",
      "\n",
      "            V7        V8        V9  ...       V21       V22       V23  \\\n",
      "0     0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
      "4     0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
      "8     0.370145  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233   \n",
      "12   -0.689405 -0.227487 -2.094011  ... -0.231809 -0.483285  0.084668   \n",
      "16   -0.586057  0.189380  0.782333  ... -0.024612  0.196002  0.013802   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1508  0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
      "1512  0.879016 -0.156590 -0.142117  ...  0.066353  0.281378 -0.257966   \n",
      "1516 -2.110183  0.788347  0.958809  ...  0.422452  1.195394  0.297836   \n",
      "1520  0.094272 -0.210300  0.014455  ... -0.286856 -0.820658  0.127663   \n",
      "1524  0.269083  0.140631  0.023464  ... -0.179545 -0.192036 -0.261879   \n",
      "\n",
      "           V24       V25       V26       V27       V28  Amount  Class  \n",
      "0     0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "4     0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
      "8     1.011592  0.373205 -0.384157  0.011747  0.142404   93.20      0  \n",
      "12    0.392831  0.161135 -0.354990  0.026416  0.042422  121.50      0  \n",
      "16    0.103758  0.364298 -0.382261  0.092809  0.037051   12.99      0  \n",
      "...        ...       ...       ...       ...       ...     ...    ...  \n",
      "1508 -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
      "1512  0.385384  0.391117 -0.453853 -0.104448 -0.125765    1.00      1  \n",
      "1516 -0.857105 -0.219322  0.861019 -0.124622 -0.171060    1.50      1  \n",
      "1520  0.343128  0.221120  0.094391 -0.022189  0.030944    1.29      1  \n",
      "1524 -0.237477 -0.335040  0.240323 -0.345129 -0.383563    1.00      1  \n",
      "\n",
      "[382 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "#Systematic Sampling\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Define the sampling interval\n",
    "k = 4\n",
    "\n",
    "# Generate the systematic sample\n",
    "systematic_sample = balanced_data.iloc[::k, :]\n",
    "\n",
    "# Print the systematic sample\n",
    "print(systematic_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Random Forest Classifier on the systematic sample is: 0.9782608695652174\n"
     ]
    }
   ],
   "source": [
    "#Random forest classifier\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the sampling interval\n",
    "k = 10\n",
    "\n",
    "# Generate the systematic sample\n",
    "systematic_sample = balanced_data.iloc[::k, :]\n",
    "\n",
    "# Split the data into features and target\n",
    "X = systematic_sample.drop('Class', axis=1)\n",
    "y = systematic_sample['Class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the Random Forest Classifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy of the model\n",
    "print(\"The accuracy of the Random Forest Classifier on the systematic sample is:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression model on the systematic sample is: 0.7391304347826086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the sampling interval\n",
    "k = 4\n",
    "\n",
    "# Generate the systematic sample\n",
    "systematic_sample = balanced_data.iloc[::k, :]\n",
    "\n",
    "# Define the logistic regression model\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy of the model\n",
    "print(\"The accuracy of the Logistic Regression model on the systematic sample is:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the KNN classifier model on the systematic sample is: 0.8043478260869565\n"
     ]
    }
   ],
   "source": [
    "#KNN Classifier\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the sampling interval\n",
    "k = 4\n",
    "\n",
    "# Define the KNN classifier model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy of the model\n",
    "print(\"The accuracy of the KNN classifier model on the systematic sample is:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9782608695652174\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Create a systematic sample of the data\n",
    "sampling_interval = 4\n",
    "\n",
    "# Create the decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy of the classifier\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8260869565217391\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Create a systematic sample of the data\n",
    "sampling_interval = 4\n",
    "\n",
    "# Create the SVM classifier\n",
    "clf = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy of the classifier\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clearly, We can see that Random Forest Classifier give us the highest value of accuracy i.e. 100% in Random Sampling Technique.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "132a366eefc41a8a6b492ab3031f555c56570ad979b771a357e90790c4ef93b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
